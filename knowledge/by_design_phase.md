# AI & Design Research by Design Phase


## Establishing a Need

### Key themes
- This phase involves framing the design problem by externalizing and organizing domain-specific knowledge to identify genuine user or stakeholder needs.
- Designers must navigate bounded rationality by selectively gathering relevant information, often confronting incomplete or biased data.
- Collaborative sense-making and reflective framing are critical, as initial problem definitions emerge from interpreting contextual cues and domain knowledge.
- Ethical considerations and inclusivity begin to surface here, as recognizing diverse user perspectives and potential biases influences the scope and direction of the design need.

### Recent developments
- AI facilitates richer externalization and representation of complex, domain-specific knowledge through tailored knowledge graphs and structured agents, helping designers to map problem spaces with greater precision.
- Mixed reality technologies and interactive visualization tools enhance designers’ capacity for immersive engagement with contextual data, supporting deeper reflection-in-action during need establishment.
- Advances in AI-driven data synthesis, such as generating diverse and equitable datasets, assist in broadening the inclusivity of initial design considerations and mitigating fixation on narrow problem framings.
- Hierarchical task abstraction models help capture and simulate domain workflows, enabling designers to better understand procedural constraints and interdependencies early in the process.
- Emerging frameworks for human-AI collaboration emphasize transparent, explainable AI interactions that maintain a balance of control, fostering co-evolution of problem definition through iterative negotiation between human insight and AI suggestions.

### Open research questions
- How do AI-enabled knowledge externalization tools influence designers’ framing and reframing of ambiguous or ill-structured needs?
- In what ways can mixed reality and interactive data overlays cultivate richer reflection-in-action without overwhelming or distracting designers?
- How might AI-generated diverse datasets or synthetic scenarios reduce cognitive fixation and broaden the search space during need articulation?
- What models of human-AI collaboration best support the co-construction of design problems while preserving human agency and critical judgement?
- How can ethical and geopolitical considerations around AI’s role in knowledge construction be integrated into early design cognition to ensure more responsible innovation?

## Analysis of Task

### Key themes
- Designers engage in framing the problem space by identifying relevant task demands, often navigating competing sub-demands and contextual constraints.
- Task analysis involves decomposing complex workflows into manageable components while recognizing interdependencies among agents, objects, and environment.
- Reflection-in-action is critical as designers interpret ambiguous or noisy input data, requiring iterative sensemaking and validation.
- Externalization through benchmarks, annotated datasets, or task representations supports shared understanding and evaluation of task complexity.
- Collaboration and negotiation of task preferences emerge, especially in multi-agent or user-centered contexts, balancing autonomy and control.

### Recent developments
- AI-driven contextualization enables dynamic and position-aware task optimization, allowing designers to adapt analysis to nuanced environments (e.g., peptide design, navigation).
- Integration of multi-dimensional data (visual, spatial, symbolic) facilitates richer task representations, supporting human-object interaction insights and multimodal fusion.
- Large-scale foundation models and benchmarks are shifting task analysis from static to operational reliability, emphasizing real-world efficacy over narrow accuracy.
- Embodied and Bayesian approaches in assistive technologies illustrate the integration of cognitive principles in continuous intent prediction and motion control, grounding task analysis in user embodiment.
- Formalization of decision-making, including multi-agent coordination and preference integration, enhances the systematic capture of complex task interrelations.
- Advances in real-time data processing (e.g., optical correction, aerosol mass spectrometry) demonstrate the move towards on-the-fly task interpretation supporting timely decisions.
- Ethical and participatory frameworks emphasize the role of diverse stakeholder perspectives in defining task parameters and assessing fairness in data representation.

### Open research questions
- How do designers balance the evolving granularity of task decomposition with the need for holistic understanding in ambiguous or noisy contexts?
- In what ways can AI-augmented analysis support designers in negotiating task preferences and managing competing priorities within multi-agent or collaborative settings?
- How might dynamic and embodied representations of task demands reshape reflection-in-action during early design framing?
- What mechanisms can ensure transparency and accountability when AI systems influence task framing and decision-making autonomy?
- How can benchmarks and datasets better capture operational reliability and ethical considerations without reducing complex tasks to oversimplified metrics?
- To what extent do externalized task models facilitate or constrain designer creativity and flexibility amid changing user or environmental conditions?

## Concept Design

### Key themes
- Concept design involves iterative framing and reframing of design problems through externalisation of ideas, often as sketches, models, or spatial configurations.
- Designers engage in reflection-in-action, adjusting their concepts responsively based on emergent insights.
- Collaboration and multi-modal representation play a critical role, enabling diverse viewpoints to shape the evolving concept.
- Problem-solution co-evolution is central: as the design space is explored, both problem understanding and solution possibilities expand and influence each other.
- Maintaining openness to divergent ideas while avoiding fixation on early concepts supports innovation and creativity in this phase.

### Recent developments
- AI tools enabling rapid generation and retrieval-enhanced synthesis of 3D meshes, spatial layouts, and environments support externalisation and exploration of volumetric design ideas with less manual effort. This accelerates the iterative cycles of model refinement and variation.
- Text-to-3D world generation lowers technical barriers, expanding the pool of contributors able to engage in early-stage spatial storytelling and environment conceptualisation, thus democratizing participation.
- Context-aware AI agents and dynamic optimization frameworks introduce new ways to support situated design adjustments, enabling designers to explore design alternatives that respond to evolving constraints without restarting from scratch.
- Advances in motion planning and physics-aware verification embed a layer of embodied cognition and physical plausibility earlier in concept exploration, supporting reflection on real-world feasibility directly within generative outputs.
- Emerging ontologies and agent architectures provide frameworks to formalize and simulate design rationality and multi-agent collaboration, potentially enriching negotiation and coordination during concept development.
- Mixed reality and interactive live streaming enrich co-design and stakeholder engagement through immersive, participatory experiences that make early concepts tangible and socially situated.
- Efforts addressing dataset diversity and equity highlight a growing awareness that conceptual design tools must incorporate social and cultural inclusivity as foundational considerations.

### Open research questions
- How does the integration of AI-driven generation influence the reflective practice of sketching and modelling? Does it shift the balance between intuitive exploration and analytical evaluation?
- In what ways can AI augment designers’ situational awareness of problem contexts while retaining human agency in framing and reframing?
- How might concept design benefit from agentic AI systems that can autonomously propose, critique, and negotiate design alternatives within multi-stakeholder settings?
- What are effective strategies to prevent AI-supported ideation tools from inducing fixation or premature convergence on suboptimal design paths?
- How do embodied and physics-aware generative systems reshape designers’ engagement with materiality and feasibility during concept generation?
- To what extent can mixed reality tools transform collaboration dynamics and reflection-in-action by extending ideation beyond traditional studios?
- How can inclusivity and ethical considerations be embedded into AI-supported conceptual design processes to ensure socially equitable innovation?

## Embodiment design

### Key themes
- Designers engage deeply with the spatial and physical instantiation of concepts, affecting how ideas evolve through tangible form.
- Embodiment involves iterative externalisation of shapes and structures, where designers balance fidelity, feasibility, and expressiveness in 3D representations.
- Incremental editing and refinement of digital forms support reflection-in-action, enabling designers to revisit and reshape problem and solution spaces dynamically.
- Collaboration with domain-specific tools and agents scaffolds complex workflows, emphasizing task structure understanding.
- Representation of physical properties and constraints (optical aberrations, mechanical dynamics) is critical for aligning form with functional behavior.
- Engagement with interactive and mixed-reality environments augments designers’ perceptual immersion, fostering richer contextualisation of embodied designs.

### Recent developments
- AI-driven mesh generation and retrieval-augmented frameworks enable more fluid, incremental manipulation of 3D forms, reducing cognitive load tied to maintaining global consistency.
- Text-to-3D scene generation tools democratize access to embodiment design by lowering the barrier of 3D modeling skills, allowing abstract framing to translate more directly into spatial form.
- Context-aware optimization frameworks in peptide design illustrate how dynamic, position-sensitive feedback can support embodiment tasks beyond traditional physical artifacts.
- Hierarchical task abstraction mechanisms facilitate better alignment of AI agents with the procedural and structural complexity inherent in embodiment workflows.
- Mixed Reality integration enriches embodiment by overlaying interactive layers onto physical or digital artefacts, expanding the reflective conversation with the design context.
- Advances in model predictive control and physics-aware generative techniques provide real-time, context-sensitive corrections and enhancements, bridging the gap between virtual models and their potential physical behaviors.
- Efficient model pruning and edge deployment methods ensure embodiment tools can be more accessible in varied contexts, supporting situated design activities.
- Novel computing architectures tailored to energy efficiency suggest future embodiment tools may increasingly support complex computational simulations in situ, enhancing real-time feedback.

### Open research questions
- How does incremental AI-supported mesh generation influence designers’ reflective cycles and evolving problem framing during embodiment?
- In what ways can AI-mediated retrieval and sketch-guided verification reduce fixation effects while preserving designer agency and conceptual diversity?
- How might designers best integrate mixed reality overlays with traditional embodiment representations to enrich knowing-in-action without cognitive overload?
- What task structures and abstraction layers most effectively scaffold human-AI collaboration in complex, embodied design tasks involving multiple constraints?
- How can AI systems dynamically balance fidelity to physical laws and allowance for creative exploration during real-time embodiment iteration?
- What forms of externalisation and representation best support collaborative embodiment design when mediated by adaptive AI agents or domain-specific tools?
- How do design cognition strategies change when embodiment moves beyond physical product artifacts into molecular or quantum domains that require distinct material reasoning?

## Detail design

### Key themes
- Designers refine and specify solutions with high fidelity, requiring attention to fine-grained constraints and affordances.
- This phase demands intensive reflection-in-action, where designers iteratively test, adjust, and resolve emergent technical and form-related issues.
- External representations (detailed drawings, prototypes) play a critical role in making implicit knowledge explicit and in supporting collaborative validation.
- Managing complexity and preventing fixation on suboptimal details is central, necessitating strategies for flexible reframing within a bounded problem space.

### Recent developments
- Advances in AI systems training enable faster, more capable generative models that can support detailed design exploration through richer, context-aware suggestions.
- Large-scale models trained on high-performance platforms allow integration of extensive domain knowledge, assisting designers in navigating intricate technical specifications and variant combinations.
- These developments facilitate real-time augmentation of reflection-in-action by providing on-demand, diverse alternatives or by simulating the consequences of design choices at a detailed level.
- The underlying hardware improvements improve responsiveness and scalability of intelligent design assistants, making them more practical for iterative, detail-oriented workflows.

### Open research questions
- How do AI-augmented tools influence designers' reflective practice when refining complex details? Do they foster deeper understanding or risk automation bias?
- In what ways can AI support externalization strategies during the detail design phase without constraining creative exploration or causing fixation?
- How can collaborative negotiation of design details be mediated to balance AI-generated proposals with diverse human expert inputs?
- What cognitive shifts occur when designers interact with AI systems capable of handling large problem spaces and multiple interconnected constraints in real time?

## Implementation

### Key themes
- Implementation involves the translation of design concepts into working artifacts, emphasizing performance, reliability, and real-world constraints.
- Designers engage in iterative testing, refinement, and adaptation as they negotiate between domain-specific requirements and operational realities.
- There is a strong focus on externalizing procedural knowledge through hierarchical task structures and modularity to manage complexity.
- Reflection-in-action is evident in troubleshooting and correcting system behaviors during deployment, often requiring adjustment of control strategies or integration methods.
- Collaboration with multi-agent or embedded systems necessitates coordination and the alignment of mental models, especially for dynamic and interactive components.

### Recent developments
- AI enables progressive automation of mesh generation and design geometry, supporting incremental editing without restarting the design cycle, which aligns with the reflective iteration process.
- Domain-specific agents constructed through hierarchical abstraction facilitate more structured workflows, easing designer cognitive load by externalizing task complexity and improving procedural correctness.
- Autonomous decision-making systems now accommodate user preferences and multi-demand scenarios, enhancing embodied cognition in assistive and interactive technologies.
- Advances in benchmarks assessing operational reliability highlight the shift from mere functional correctness toward trustworthiness and resilience, reflecting the designer’s concern for robust real-world performance.
- Methods integrating retrieval and pre-trained knowledge libraries support rapid adaptation to new domains, reducing fixation by allowing designers to recover relevant past solutions during implementation.
- Visual and sensor data processing improvements (e.g., in optical corrections, environmental monitoring) indicate tighter coupling between perception and action within design artifacts, fostering seamless reflectivity on system performance.
- Emerging quantum and Bayesian learning techniques suggest new frontiers for handling uncertainty and incomplete data in deployment, implying shifts in how designers engage with real-time system behaviors.
- Mixed reality and interactive streaming tools augment user engagement with implemented designs, indicating expanded roles for situated presentation and reflection in cultural heritage contexts.

### Open research questions
- How does the introduction of AI-driven hierarchical agents influence designers’ reflective control over complex workflows and their ability to adapt plans in real time?
- In what ways might AI-augmented externalization methods change the nature of troubleshooting and iteration during implementation, particularly in embedded or multi-agent systems?
- How can designers balance automation with the need for serendipitous reflection-in-action to prevent premature commitment in implementation?
- What cognitive strategies support designers’ interpretation and integration of AI-generated procedural knowledge without losing domain expertise or critical oversight?
- How might mixed reality and interactive visualizations during implementation reshape designers’ situational awareness and collaborative communication with stakeholders?
- What frameworks can better capture the tacit knowledge embedded in operational reliability decisions, and how can these be integrated with AI systems for continuous improvement?
- How does the interplay between task abstraction and embodied decision-making impact creativity and error recovery in assistive and interactive design implementations?