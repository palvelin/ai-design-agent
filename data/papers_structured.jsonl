{"id": "http://arxiv.org/abs/2511.16807v1", "title": "Mesh RAG: Retrieval Augmentation for Autoregressive Mesh Generation", "abstract": "3D meshes are a critical building block for applications ranging from industrial design and gaming to simulation and robotics. Traditionally, meshes are crafted manually by artists, a process that is time-intensive and difficult to scale. To automate and accelerate this asset creation, autoregressive models have emerged as a powerful paradigm for artistic mesh generation. However, current methods to enhance quality typically rely on larger models or longer sequences that result in longer generation time, and their inherent sequential nature imposes a severe quality-speed trade-off. This sequential dependency also significantly complicates incremental editing. To overcome these limitations, we propose Mesh RAG, a novel, training-free, plug-and-play framework for autoregressive mesh generation models. Inspired by RAG for language models, our approach augments the generation process by leveraging point cloud segmentation, spatial transformation, and point cloud registration to retrieve, generate, and integrate mesh components. This retrieval-based approach decouples generation from its strict sequential dependency, facilitating efficient and parallelizable inference. We demonstrate the wide applicability of Mesh RAG across various foundational autoregressive mesh generation models, showing it significantly enhances mesh quality, accelerates generation speed compared to sequential part prediction, and enables incremental editing, all without model retraining.", "authors": ["Xiatao Sun", "Chen Liang", "Qian Wang", "Daniel Rakita"], "year": 2025, "source": "arxiv", "published": "2025-11-20T21:13:56", "categories": ["cs.CV", "cs.AI"], "design_phase": [], "ai_roles": [], "representations": [], "research_type": [], "summary_short": "3D meshes are a critical building block for applications ranging from industrial design and gaming to simulation and robotics. Traditionally, meshes are crafted manually by artists, a process that is time-intensive and difficult to scale. To automate and accelerate this asset creation, autoregressiv", "implications_for_design_research": [], "tags": []}
{"id": "http://arxiv.org/abs/2511.16814v1", "title": "Stable diffusion models reveal a persisting human and AI gap in visual creativity", "abstract": "While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two prompting conditions with varying human input: high for Human Inspired, low for Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the resulting images. We found a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. Increased human guidance strongly improved GenAI's creative output, bringing its productions close to those of Non Artists. Notably, human and AI raters also showed vastly different creativity judgment patterns. These results suggest that, in contrast to language centered tasks, GenAI models may face unique challenges in visual domains, where creativity depends on perceptual nuance and contextual sensitivity, distinctly human capacities that may not be readily transferable from language models.", "authors": ["Silvia Rondini", "Claudia Alvarez-Martin", "Paula Angermair-Barkai", "Olivier Penacchio", "M. Paz", "Matthew Pelowski", "Dan Dediu", "Antoni Rodriguez-Fornells", "Xim Cerda-Company"], "year": 2025, "source": "arxiv", "published": "2025-11-20T21:33:08", "categories": ["cs.AI", "cs.HC"], "design_phase": [], "ai_roles": [], "representations": [], "research_type": [], "summary_short": "While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two promptin", "implications_for_design_research": [], "tags": []}
{"id": "http://arxiv.org/abs/2511.16825v1", "title": "WorldGen: From Text to Traversable and Interactive 3D Worlds", "abstract": "We introduce WorldGen, a system that enables the automatic creation of large-scale, interactive 3D worlds directly from text prompts. Our approach transforms natural language descriptions into traversable, fully textured environments that can be immediately explored or edited within standard game engines. By combining LLM-driven scene layout reasoning, procedural generation, diffusion-based 3D generation, and object-aware scene decomposition, WorldGen bridges the gap between creative intent and functional virtual spaces, allowing creators to design coherent, navigable worlds without manual modeling or specialized 3D expertise. The system is fully modular and supports fine-grained control over layout, scale, and style, producing worlds that are geometrically consistent, visually rich, and efficient to render in real time. This work represents a step towards accessible, generative world-building at scale, advancing the frontier of 3D generative AI for applications in gaming, simulation, and immersive social environments.", "authors": ["Dilin Wang", "Hyunyoung Jung", "Tom Monnier", "Kihyuk Sohn", "Chuhang Zou", "Xiaoyu Xiang", "Yu-Ying Yeh", "Di Liu", "Zixuan Huang", "Thu Nguyen-Phuoc", "Yuchen Fan", "Sergiu Oprea", "Ziyan Wang", "Roman Shapovalov", "Nikolaos Sarafianos", "Thibault Groueix", "Antoine Toisoul", "Prithviraj Dhar", "Xiao Chu", "Minghao Chen", "Geon Yeong Park", "Mahima Gupta", "Yassir Azziz", "Rakesh Ranjan", "Andrea Vedaldi"], "year": 2025, "source": "arxiv", "published": "2025-11-20T22:13:18", "categories": ["cs.CV", "cs.AI"], "design_phase": [], "ai_roles": [], "representations": [], "research_type": [], "summary_short": "We introduce WorldGen, a system that enables the automatic creation of large-scale, interactive 3D worlds directly from text prompts. Our approach transforms natural language descriptions into traversable, fully textured environments that can be immediately explored or edited within standard game en", "implications_for_design_research": [], "tags": []}
{"id": "http://arxiv.org/abs/2511.16912v1", "title": "PepEVOLVE: Position-Aware Dynamic Peptide Optimization via Group-Relative Advantage", "abstract": "Macrocyclic peptides are an emerging modality that combines biologics-like affinity with small-molecule-like developability, but their vast combinatorial space and multi-parameter objectives make lead optimization slow and challenging. Prior generative approaches such as PepINVENT require chemists to pre-specify mutable positions for optimization, choices that are not always known a priori, and rely on static pretraining and optimization algorithms that limit the model's ability to generalize and effectively optimize peptide sequences. We introduce PepEVOLVE, a position-aware, dynamic framework that learns both where to edit and how to dynamically optimize peptides for multi-objective improvement. PepEVOLVE (i) augments pretraining with dynamic masking and CHUCKLES shifting to improve generalization, (ii) uses a context-free multi-armed bandit router that discovers high-reward residues, and (iii) couples a novel evolving optimization algorithm with group-relative advantage to stabilize reinforcement updates. During in silico evaluations, the router policy reliably learns and concentrates probability on chemically meaningful sites that influence the peptide's properties. On a therapeutically motivated Rev-binding macrocycle benchmark, PepEVOLVE outperformed PepINVENT by reaching higher mean scores (approximately 0.8 vs. 0.6), achieving best candidates with a score of 0.95 (vs. 0.87), and converging in fewer steps under the task of optimizing permeability and lipophilicity with structural constraints. Overall, PepEVOLVE offers a practical, reproducible path to peptide lead optimization when optimal edit sites are unknown, enabling more efficient exploration and improving design quality across multiple objectives.", "authors": ["Trieu Nguyen", "Hao-Wei Pang", "Shasha Feng"], "year": 2025, "source": "arxiv", "published": "2025-11-21T02:51:15", "categories": ["cs.LG", "cs.AI"], "design_phase": [], "ai_roles": [], "representations": [], "research_type": [], "summary_short": "Macrocyclic peptides are an emerging modality that combines biologics-like affinity with small-molecule-like developability, but their vast combinatorial space and multi-parameter objectives make lead optimization slow and challenging. Prior generative approaches such as PepINVENT require chemists t", "implications_for_design_research": [], "tags": []}
{"id": "http://arxiv.org/abs/2511.17012v1", "title": "Supervised Fine Tuning of Large Language Models for Domain Specific Knowledge Graph Construction:A Case Study on Hunan's Historical Celebrities", "abstract": "Large language models and knowledge graphs offer strong potential for advancing research on historical culture by supporting the extraction, analysis, and interpretation of cultural heritage. Using Hunan's modern historical celebrities shaped by Huxiang culture as a case study, pre-trained large models can help researchers efficiently extract key information, including biographical attributes, life events, and social relationships, from textual sources and construct structured knowledge graphs. However, systematic data resources for Hunan's historical celebrities remain limited, and general-purpose models often underperform in domain knowledge extraction and structured output generation in such low-resource settings. To address these issues, this study proposes a supervised fine-tuning approach for enhancing domain-specific information extraction. First, we design a fine-grained, schema-guided instruction template tailored to the Hunan historical celebrities domain and build an instruction-tuning dataset to mitigate the lack of domain-specific training corpora. Second, we apply parameter-efficient instruction fine-tuning to four publicly available large language models - Qwen2.5-7B, Qwen3-8B, DeepSeek-R1-Distill-Qwen-7B, and Llama-3.1-8B-Instruct - and develop evaluation criteria for assessing their extraction performance. Experimental results show that all models exhibit substantial performance gains after fine-tuning. Among them, Qwen3-8B achieves the strongest results, reaching a score of 89.3866 with 100 samples and 50 training iterations. This study provides new insights into fine-tuning vertical large language models for regional historical and cultural domains and highlights their potential for cost-effective applications in cultural heritage knowledge extraction and knowledge graph construction.", "authors": ["Junjie Hao", "Chun Wang", "Ying Qiao", "Qiuyue Zuo", "Qiya Song", "Hua Ma", "Xieping Gao"], "year": 2025, "source": "arxiv", "published": "2025-11-21T07:30:20", "categories": ["cs.CL", "cs.AI"], "design_phase": ["Establishing a need", "Concept design", "Implementation"], "ai_roles": ["evaluation", "optimization", "analysis"], "representations": ["text", "data visualization", "schema"], "research_type": ["tool development", "case study"], "summary_short": "This study investigates the use of supervised fine-tuning of large language models to construct knowledge graphs of Hunan's historical celebrities. It addresses the challenges of limited domain-specific data by designing customized instruction templates and enhancing model performance through parameter-efficient techniques.", "implications_for_design_research": ["Highlights the necessity of domain-specific training datasets for effective AI applications.", "Demonstrates the potential of AI in cultural heritage knowledge extraction.", "Suggests a framework for fine-tuning models in low-resource domains."], "tags": ["knowledge-graph", "domain-adaptation", "cultural-heritage", "fine-tuning"]}
{"id": "http://arxiv.org/abs/2511.17043v1", "title": "MedImageInsight for Thoracic Cavity Health Classification from Chest X-rays", "abstract": "Chest radiography remains one of the most widely used imaging modalities for thoracic diagnosis, yet increasing imaging volumes and radiologist workload continue to challenge timely interpretation. In this work, we investigate the use of MedImageInsight, a medical imaging foundational model, for automated binary classification of chest X-rays into Normal and Abnormal categories. Two approaches were evaluated: (1) fine-tuning MedImageInsight for end-to-end classification, and (2) employing the model as a feature extractor for a transfer learning pipeline using traditional machine learning classifiers. Experiments were conducted using a combination of the ChestX-ray14 dataset and real-world clinical data sourced from partner hospitals. The fine-tuned classifier achieved the highest performance, with an ROC-AUC of 0.888 and superior calibration compared to the transfer learning models, demonstrating performance comparable to established architectures such as CheXNet. These results highlight the effectiveness of foundational medical imaging models in reducing task-specific training requirements while maintaining diagnostic reliability. The system is designed for integration into web-based and hospital PACS workflows to support triage and reduce radiologist burden. Future work will extend the model to multi-label pathology classification to provide preliminary diagnostic interpretation in clinical environments.", "authors": ["Rama Krishna Boya", "Mohan Kireeti Magalanadu", "Azaruddin Palavalli", "Rupa Ganesh Tekuri", "Amrit Pattanayak", "Prasanthi Enuga", "Vignesh Esakki Muthu", "Vivek Aditya Boya"], "year": 2025, "source": "arxiv", "published": "2025-11-21T08:42:20", "categories": ["eess.IV", "cs.AI", "cs.CV"], "design_phase": ["Analysis of task", "Implementation"], "ai_roles": ["evaluation", "optimization"], "representations": ["data visualization", "interface"], "research_type": ["tool development", "case study"], "summary_short": "This study explores the use of MedImageInsight for automating the classification of chest X-rays into Normal and Abnormal categories. The results demonstrate the model's effectiveness in enhancing diagnostic reliability while reducing the workload of radiologists.", "implications_for_design_research": ["Foundation models can ease the implementation of classification tasks in medical imaging.", "Automated systems can significantly reduce radiologist workload and improve diagnostic processes.", "Integration into existing workflows is crucial for practical applications in clinical settings."], "tags": ["medical-imaging", "machine-learning", "workflow-integration"]}
{"id": "http://arxiv.org/abs/2511.17045v1", "title": "RacketVision: A Multiple Racket Sports Benchmark for Unified Ball and Racket Analysis", "abstract": "We introduce RacketVision, a novel dataset and benchmark for advancing computer vision in sports analytics, covering table tennis, tennis, and badminton. The dataset is the first to provide large-scale, fine-grained annotations for racket pose alongside traditional ball positions, enabling research into complex human-object interactions. It is designed to tackle three interconnected tasks: fine-grained ball tracking, articulated racket pose estimation, and predictive ball trajectory forecasting. Our evaluation of established baselines reveals a critical insight for multi-modal fusion: while naively concatenating racket pose features degrades performance, a CrossAttention mechanism is essential to unlock their value, leading to trajectory prediction results that surpass strong unimodal baselines. RacketVision provides a versatile resource and a strong starting point for future research in dynamic object tracking, conditional motion forecasting, and multimodal analysis in sports. Project page at https://github.com/OrcustD/RacketVision", "authors": ["Linfeng Dong", "Yuchen Yang", "Hao Wu", "Wei Wang", "Yuenan HouZhihang Zhong", "Xiao Sun"], "year": 2025, "source": "arxiv", "published": "2025-11-21T08:44:33", "categories": ["cs.CV", "cs.AI", "cs.MM"], "design_phase": ["Analysis of task", "Concept design", "Implementation"], "ai_roles": ["evaluation", "analysis", "optimization"], "representations": ["data visualization", "image", "code"], "research_type": ["tool development", "methodology"], "summary_short": "RacketVision introduces a comprehensive dataset and benchmark aimed at enhancing computer vision in racket sports. It provides detailed annotations for racket pose and ball positions, facilitating research on human-object interactions and predictive analytics in sports.", "implications_for_design_research": ["Enhances understanding of multimodal fusion in sports analytics.", "Provides a foundation for future dynamic object tracking research.", "Offers a new benchmark for evaluating computer vision methods in sports."], "tags": ["computer-vision", "sports-analytics", "multimodal-fusion", "object-tracking"]}
{"id": "http://arxiv.org/abs/2511.17112v1", "title": "Dissecting Quantum Reinforcement Learning: A Systematic Evaluation of Key Components", "abstract": "Parameterised quantum circuit (PQC) based Quantum Reinforcement Learning (QRL) has emerged as a promising paradigm at the intersection of quantum computing and reinforcement learning (RL). By design, PQCs create hybrid quantum-classical models, but their practical applicability remains uncertain due to training instabilities, barren plateaus (BPs), and the difficulty of isolating the contribution of individual pipeline components. In this work, we dissect PQC based QRL architectures through a systematic experimental evaluation of three aspects recurrently identified as critical: (i) data embedding strategies, with Data Reuploading (DR) as an advanced approach; (ii) ansatz design, particularly the role of entanglement; and (iii) post-processing blocks after quantum measurement, with a focus on the underexplored Output Reuse (OR) technique. Using a unified PPO-CartPole framework, we perform controlled comparisons between hybrid and classical agents under identical conditions. Our results show that OR, though purely classical, exhibits distinct behaviour in hybrid pipelines, that DR improves trainability and stability, and that stronger entanglement can degrade optimisation, offsetting classical gains. Together, these findings provide controlled empirical evidence of the interplay between quantum and classical contributions, and establish a reproducible framework for systematic benchmarking and component-wise analysis in QRL.", "authors": ["Javier Lazaro", "Juan-Ignacio Vazquez", "Pablo Garcia-Bringas"], "year": 2025, "source": "arxiv", "published": "2025-11-21T10:21:39", "categories": ["quant-ph", "cs.LG"], "design_phase": ["Analysis of task", "Concept design", "Embodiment design"], "ai_roles": ["evaluation", "analysis"], "representations": ["data visualization", "code", "prototype"], "research_type": ["tool development", "methodology"], "summary_short": "This paper systematically evaluates key components of parameterised quantum circuit based Quantum Reinforcement Learning (QRL). It focuses on data embedding strategies, ansatz design, and post-processing techniques, revealing insights into their influence on trainability and optimization in hybrid quantum-classical models.", "implications_for_design_research": ["Establishes a framework for systematic benchmarking in quantum reinforcement learning.", "Highlights the importance of component isolation in analyzing quantum-classical systems.", "Suggests that hybrid models can exhibit unique behaviors warranting further investigation."], "tags": ["quantum-reinforcement-learning", "tool-development", "methodology", "systematic-evaluation"]}
{"id": "http://arxiv.org/abs/2511.17126v1", "title": "OmniLens++: Blind Lens Aberration Correction via Large LensLib Pre-Training and Latent PSF Representation", "abstract": "Emerging deep-learning-based lens library pre-training (LensLib-PT) pipeline offers a new avenue for blind lens aberration correction by training a universal neural network, demonstrating strong capability in handling diverse unknown optical degradations. This work proposes the OmniLens++ framework, which resolves two challenges that hinder the generalization ability of existing pipelines: the difficulty of scaling data and the absence of prior guidance characterizing optical degradation. To improve data scalability, we expand the design specifications to increase the degradation diversity of the lens source, and we sample a more uniform distribution by quantifying the spatial-variation patterns and severity of optical degradation. In terms of model design, to leverage the Point Spread Functions (PSFs), which intuitively describe optical degradation, as guidance in a blind paradigm, we propose the Latent PSF Representation (LPR). The VQVAE framework is introduced to learn latent features of LensLib's PSFs, which is assisted by modeling the optical degradation process to constrain the learning of degradation priors. Experiments on diverse aberrations of real-world lenses and synthetic LensLib show that OmniLens++ exhibits state-of-the-art generalization capacity in blind aberration correction. Beyond performance, the AODLibpro is verified as a scalable foundation for more effective training across diverse aberrations, and LPR can further tap the potential of large-scale LensLib. The source code and datasets will be made publicly available at https://github.com/zju-jiangqi/OmniLens2.", "authors": ["Qi Jiang", "Xiaolong Qian", "Yao Gao", "Lei Sun", "Kailun Yang", "Zhonghua Yi", "Wenyong Li", "Ming-Hsuan Yang", "Luc Van Gool", "Kaiwei Wang"], "year": 2025, "source": "arxiv", "published": "2025-11-21T10:41:54", "categories": ["eess.IV", "cs.CV", "cs.LG", "physics.optics"], "design_phase": ["Establishing a need", "Analysis of task", "Concept design", "Embodiment design", "Implementation"], "ai_roles": ["evaluation", "optimization", "analysis"], "representations": ["data visualization", "prototype", "code"], "research_type": ["tool development", "methodology"], "summary_short": "The OmniLens++ framework introduces a new blind lens aberration correction method leveraging a deep-learning-based lens library pre-training approach. It enhances generalization capability by addressing data scalability and utilizing a novel Latent PSF Representation.", "implications_for_design_research": ["Demonstrates the efficacy of neural networks in optical design applications.", "Highlights the importance of scalable data in improving model training.", "Introduces innovative representations of optical degradation to guide design processes."], "tags": ["lens-aberration", "deep-learning", "optical-design", "model-generalization"]}
{"id": "http://arxiv.org/abs/2511.17127v1", "title": "Training Foundation Models on a Full-Stack AMD Platform: Compute, Networking, and System Design", "abstract": "We report on the first large-scale mixture-of-experts (MoE) pretraining study on pure AMD hardware, utilizing both MI300X GPUs with Pollara interconnect. We distill practical guidance for both systems and model design. On the systems side, we deliver a comprehensive cluster and networking characterization: microbenchmarks for all core collectives (all-reduce, reduce-scatter, all-gather, broadcast) across message sizes and GPU counts on Pollara. To our knowledge, this is the first at this scale. We further provide MI300X microbenchmarks on kernel sizing and memory bandwidth to inform model design. On the modeling side, we introduce and apply MI300X-aware transformer sizing rules for attention and MLP blocks and justify MoE widths that jointly optimize training throughput and inference latency. We describe our training stack in depth, including often-ignored utilities such as fault-tolerance and checkpoint-reshaping, as well as detailed information on our training recipe. We also provide a preview of our model architecture and base model - ZAYA1 (760M active, 8.3B total parameters MoE) - which will be further improved upon in forthcoming papers. ZAYA1-base achieves performance comparable to leading base models such as Qwen3-4B and Gemma3-12B at its scale and larger, and outperforms models including Llama-3-8B and OLMoE across reasoning, mathematics, and coding benchmarks. Together, these results demonstrate that the AMD hardware, network, and software stack are mature and optimized enough for competitive large-scale pretraining.", "authors": ["Quentin Anthony", "Yury Tokpanov", "Skyler Szot", "Srivatsan Rajagopal", "Praneeth Medepalli", "Rishi Iyer", "Vasu Shyam", "Anna Golubeva", "Ansh Chaurasia", "Xiao Yang", "Tomas Figliolia", "Robert Washbourne", "Drew Thorstensen", "Amartey Pearson", "Zack Grossbart", "Jason van Patten", "Emad Barsoum", "Zhenyu Gu", "Yao Fu", "Beren Millidge"], "year": 2025, "source": "arxiv", "published": "2025-11-21T10:44:02", "categories": ["cs.CL", "cs.AI", "cs.DC"], "design_phase": ["Establishing a need", "Analysis of task", "Concept design", "Embodiment design", "Detail design"], "ai_roles": ["optimization", "evaluation", "analysis"], "representations": ["code", "prototype", "data visualization"], "research_type": ["tool development", "methodology"], "summary_short": "This paper presents a large-scale mixture-of-experts (MoE) pretraining study on AMD hardware, focusing on system and model design optimization. It includes detailed microbenchmarks and sizing rules, demonstrating competitive performance of the ZAYA1 model compared to leading base models.", "implications_for_design_research": ["Advances in system and model design can inform future AI hardware developments.", "Detailed benchmarking can serve as a foundational resource for optimizing AI training processes.", "Collaborative tools and methodologies can enhance model performance and resource efficiency."], "tags": ["amd-hardware", "model-optimization", "pretraining-study", "mixture-of-experts"]}
{"id": "http://arxiv.org/abs/2511.17129v1", "title": "Learning to Compress: Unlocking the Potential of Large Language Models for Text Representation", "abstract": "Text representation plays a critical role in tasks like clustering, retrieval, and other downstream applications. With the emergence of large language models (LLMs), there is increasing interest in harnessing their capabilities for this purpose. However, most of the LLMs are inherently causal and optimized for next-token prediction, making them suboptimal for producing holistic representations. To address this, recent studies introduced pretext tasks to adapt LLMs for text representation. Most of these tasks, however, rely on token-level prediction objectives, such as the masked next-token prediction (MNTP) used in LLM2Vec. In this work, we explore the untapped potential of context compression as a pretext task for unsupervised adaptation of LLMs. During compression pre-training, the model learns to generate compact memory tokens, which substitute the whole context for downstream sequence prediction. Experiments demonstrate that a well-designed compression objective can significantly enhance LLM-based text representations, outperforming models trained with token-level pretext tasks. Further improvements through contrastive learning produce a strong representation model (LLM2Comp) that outperforms contemporary LLM-based text encoders on a wide range of tasks while being more sample-efficient, requiring significantly less training data.", "authors": ["Yeqin Zhang", "Yizheng Zhao", "Chen Hu", "Binxing Jiao", "Daxin Jiang", "Ruihang Miao", "Cam-Tu Nguyen"], "year": 2025, "source": "arxiv", "published": "2025-11-21T10:45:44", "categories": ["cs.CL", "cs.AI"], "design_phase": ["Establishing a need", "Analysis of task", "Concept design"], "ai_roles": ["optimization", "evaluation", "analysis"], "representations": ["text", "data visualization", "code"], "research_type": ["methodology", "tool development"], "summary_short": "This paper investigates the use of context compression as a pretext task for improving text representation in large language models (LLMs). The proposed approach, LLM2Comp, demonstrates enhanced representation capabilities while being more sample-efficient compared to existing models.", "implications_for_design_research": ["The integration of compression techniques in LLMs can lead to more effective text representations.", "Optimizing for compactness in model training may redefine evaluation metrics for text representation.", "Contextual understanding should be prioritized over token-level predictions for better model outcomes."], "tags": ["text-representation", "large-language-models", "contrastive-learning"]}
{"id": "http://arxiv.org/abs/2511.17131v1", "title": "UI-CUBE: Enterprise-Grade Computer Use Agent Benchmarking Beyond Task Accuracy to Operational Reliability", "abstract": "While current Computer Use Agent (CUA) benchmarks measure task completion effectively, they provide limited assessment of enterprise deployment readiness, emphasizing functional correctness over the operational reliability required for production systems. We present UI-CUBE (UiPath Computer Use BEnchmark), a systematic benchmark comprising 226 tasks across two difficulty tiers designed to expose fundamental architectural limitations in current CUAs. Our evaluation covers simple UI interactions (136 tasks) and complex workflows including copy-paste tasks (50 tasks) and enterprise application scenarios (40 tasks), with systematic interface variation coverage, multi-resolution testing and automated validation of task success through the application state. Evaluation of five state-of-the-art models reveals a sharp capability cliff rather than gradual performance degradation. Simple UI interactions achieve 67-85% success rates (compared to 97.9% human performance), but complex workflows drop precipitously to 9-19%. Human evaluators with no prior application experience achieve only 61.2% on complex tasks despite near-perfect performance on simple tasks, establishing realistic performance ceilings. This discontinuous performance pattern -- where agents achieve 68-87% of human performance on simple tasks but only 15-32% on complex workflows -- indicates fundamental architectural limitations in memory management, hierarchical planning, and state coordination rather than incremental capability gaps addressable through better training or prompting. UI-CUBE functions as an enterprise-readiness diagnostic, revealing that while current CUAs can manipulate individual interface elements, they cannot yet function as reliable workflow automation tools. These findings provide architectural insights essential for developing production-ready CUAs capable of managing complex, multi-step enterprise processes.", "authors": ["Horia Cristescu", "Charles Park", "Trong Canh Nguyen", "Sergiu Talmacel", "Alexandru-Gabriel Ilie", "Stefan Adam"], "year": 2025, "source": "arxiv", "published": "2025-11-21T10:47:22", "categories": ["cs.SE", "cs.AI"], "design_phase": ["Analysis of task", "Implementation"], "ai_roles": ["evaluation", "analysis"], "representations": ["data visualization", "interface"], "research_type": ["tool development", "case study"], "summary_short": "The paper introduces UI-CUBE, a benchmark designed to evaluate the operational reliability of Computer Use Agents (CUAs) beyond mere task accuracy. By assessing performance across simple and complex workflows, it reveals significant gaps in current CUA architectures that hinder their deployment in enterprise environments.", "implications_for_design_research": ["Highlights the need for benchmarks that assess operational reliability, not just task completion.", "Suggests architectural improvements are essential for developing production-ready CUAs.", "Indicates that performance drop on complex tasks reflects limitations in memory and planning capabilities."], "tags": ["benchmarking", "user-interaction", "enterprise-automation", "workflow-automation"]}
{"id": "http://arxiv.org/abs/2511.17147v1", "title": "A lightweight detector for real-time detection of remote sensing images", "abstract": "Remote sensing imagery is widely used across various fields, yet real-time detection remains challenging due to the prevalence of small objects and the need to balance accuracy with efficiency. To address this, we propose DMG-YOLO, a lightweight real-time detector tailored for small object detection in remote sensing images. Specifically, we design a Dual-branch Feature Extraction (DFE) module in the backbone, which partitions feature maps into two parallel branches: one extracts local features via depthwise separable convolutions, and the other captures global context using a vision transformer with a gating mechanism. Additionally, a Multi-scale Feature Fusion (MFF) module with dilated convolutions enhances multi-scale integration while preserving fine details. In the neck, we introduce the Global and Local Aggregate Feature Pyramid Network (GLAFPN) to further boost small object detection through global-local feature fusion. Extensive experiments on the VisDrone2019 and NWPU VHR-10 datasets show that DMG-YOLO achieves competitive performance in terms of mAP, model size, and other key metrics.", "authors": ["Qianyi Wang", "Guoqiang Ren"], "year": 2025, "source": "arxiv", "published": "2025-11-21T11:11:04", "categories": ["cs.CV", "cs.AI"], "design_phase": ["Analysis of task", "Concept design", "Embodiment design"], "ai_roles": ["evaluation", "optimization", "analysis"], "representations": ["data visualization", "code", "prototype"], "research_type": ["tool development", "case study"], "summary_short": "This paper presents DMG-YOLO, a lightweight real-time detector designed for small object detection in remote sensing images. By implementing a dual-branch feature extraction module and multi-scale feature fusion, the proposed method achieves balanced accuracy and efficiency in processing complex imagery.", "implications_for_design_research": ["Advances in real-time detection methodologies can enhance effectiveness in remote sensing applications.", "The approach emphasizes the integration of local and global feature extraction techniques.", "Future tools should focus on lightweight architectures for optimized performance."], "tags": ["real-time-detection", "remote-sensing", "lightweight-model", "feature-extraction"]}
{"id": "http://arxiv.org/abs/2511.17162v1", "title": "The Belief-Desire-Intention Ontology for modelling mental reality and agency", "abstract": "The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. This paper presents a formal BDI Ontology, conceived as a modular Ontology Design Pattern (ODP) that captures the cognitive architecture of agents through beliefs, desires, intentions, and their dynamic interrelations. The ontology ensures semantic precision and reusability by aligning with foundational ontologies and best practices in modular design. Two complementary lines of experimentation demonstrate its applicability: (i) coupling the ontology with Large Language Models (LLMs) via Logic Augmented Generation (LAG) to assess the contribution of ontological grounding to inferential coherence and consistency; and (ii) integrating the ontology within the Semas reasoning platform, which implements the Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow between RDF triples and agent mental states. Together, these experiments illustrate how the BDI Ontology acts as both a conceptual and operational bridge between declarative and procedural intelligence, paving the way for cognitively grounded, explainable, and semantically interoperable multi-agent and neuro-symbolic systems operating within the Web of Data.", "authors": ["Sara Zuppiroli", "Carmelo Fabio Longo", "Anna Sofia Lippolis", "Rocco Paolillo", "Lorenzo Giammei", "Miguel Ceriani", "Francesco Poggi", "Antonio Zinilli", "Andrea Giovanni Nuzzolese"], "year": 2025, "source": "arxiv", "published": "2025-11-21T11:30:17", "categories": ["cs.AI"], "design_phase": ["Concept design", "Implementation"], "ai_roles": ["representation", "interaction", "co-creation"], "representations": ["ontology", "data visualization", "code"], "research_type": ["tool development", "theory building", "methodology"], "summary_short": "This paper presents a formal Belief-Desire-Intention (BDI) Ontology that enhances the representation of rational agency in artificial intelligence. It demonstrates the ontology's utility through experiments with Large Language Models and a reasoning platform, showing its potential for semantic interoperability and explainability in multi-agent systems.", "implications_for_design_research": ["Highlights the importance of modular design in AI ontologies.", "Demonstrates the role of ontology in improving inferential coherence in AI systems.", "Encourages integration of cognitive architectures in design methodologies."], "tags": ["bdi-ontology", "multi-agent-systems", "semantic-web"]}
{"id": "http://arxiv.org/abs/2511.17198v1", "title": "Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism", "abstract": "LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.", "authors": ["Kaiyu Li", "Jiayu Wang", "Zhi Wang", "Hui Qiao", "Weizhan Zhang", "Deyu Meng", "Xiangyong Cao"], "year": 2025, "source": "arxiv", "published": "2025-11-21T12:25:47", "categories": ["cs.AI", "cs.CV"], "design_phase": ["Establishing a need", "Concept design", "Embodiment design", "Implementation"], "ai_roles": ["idea generation", "evaluation", "optimization", "interaction"], "representations": ["text", "code", "prototype", "data visualization"], "research_type": ["methodology", "tool development", "theory building", "case study"], "summary_short": "This paper presents a Hierarchical Task Abstraction Mechanism (HTAM) for designing domain-specific agents, particularly in fields requiring structured workflows. The framework, instantiated as EarthAgent for geospatial analysis, significantly improves performance on complex planning tasks compared to established systems.", "implications_for_design_research": ["Agent design should reflect the task structure of specific domains.", "Specialized agents can enhance procedural correctness in complex workflows.", "Benchmarking methodologies are essential to evaluate agent effectiveness."], "tags": ["domain-specific-agents", "hierarchical-task-abstraction", "geospatial-analysis", "multi-agent-systems"]}
{"id": "http://arxiv.org/abs/2511.17220v1", "title": "Parrot: Persuasion and Agreement Robustness Rating of Output Truth -- A Sycophancy Robustness Benchmark for LLMs", "abstract": "This study presents PARROT (Persuasion and Agreement Robustness Rating of Output Truth), a robustness focused framework designed to measure the degradation in accuracy that occurs under social pressure exerted on users through authority and persuasion in large language models (LLMs) the phenomenon of sycophancy (excessive conformity). PARROT (i) isolates causal effects by comparing the neutral version of the same question with an authoritatively false version using a double-blind evaluation, (ii) quantifies confidence shifts toward the correct and imposed false responses using log-likelihood-based calibration tracking, and (iii) systematically classifies failure modes (e.g., robust correct, sycophantic agreement, reinforced error, stubborn error, self-correction, etc.) using an eight-state behavioral taxonomy. We evaluated 22 models using 1,302 MMLU-style multiple-choice questions across 13 domains and domain-specific authority templates. Findings show marked heterogeneity: advanced models (e.g., GPT-5, GPT-4.1, Claude Sonnet 4.5) exhibit low \"follow rates\" ($\\leq 11\\%$, GPT-5: 4\\%) and minimal accuracy loss, while older/smaller models show severe epistemic collapse (GPT-4: 80\\%, Qwen 2.5-1.5B: 94\\%). The danger is not limited to response changes; weak models reduce confidence in the correct response while increasing confidence in the imposed incorrect response. While international law and global knowledge at the domain level exhibit high fragility, elementary mathematics is relatively resilient. Consequently, we argue that the goal of \"resistance to overfitting pressure\" should be addressed as a primary objective alongside accuracy, harm avoidance, and privacy for safe deployment in the real world.", "authors": ["Yusuf Çelebi", "Mahmoud El Hussieni", "Özay Ezerceli"], "year": 2025, "source": "arxiv", "published": "2025-11-21T13:01:28", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "design_phase": ["Analysis of task", "Implementation"], "ai_roles": ["evaluation", "analysis"], "representations": ["data visualization", "prototype"], "research_type": ["methodology", "tool development"], "summary_short": "This paper introduces the PARROT framework to assess the robustness of large language models (LLMs) against social persuasion and authority-induced sycophancy. Through rigorous evaluation across various domains, it highlights significant discrepancies in model performance related to confidence and accuracy under pressure.", "implications_for_design_research": ["Highlight the need for robust evaluation frameworks for AI systems.", "Encourage the development of models with resistance to social pressures.", "Stress the importance of understanding model behavior under diverse conditions.", "Promote awareness of epistemic collapse and its impact on user confidence."], "tags": ["ai-ethics", "model-evaluation", "robustness-testing", "language-models"]}
{"id": "http://arxiv.org/abs/2511.17225v1", "title": "TP-MDDN: Task-Preferenced Multi-Demand-Driven Navigation with Autonomous Decision-Making", "abstract": "In daily life, people often move through spaces to find objects that meet their needs, posing a key challenge in embodied AI. Traditional Demand-Driven Navigation (DDN) handles one need at a time but does not reflect the complexity of real-world tasks involving multiple needs and personal choices. To bridge this gap, we introduce Task-Preferenced Multi-Demand-Driven Navigation (TP-MDDN), a new benchmark for long-horizon navigation involving multiple sub-demands with explicit task preferences. To solve TP-MDDN, we propose AWMSystem, an autonomous decision-making system composed of three key modules: BreakLLM (instruction decomposition), LocateLLM (goal selection), and StatusMLLM (task monitoring). For spatial memory, we design MASMap, which combines 3D point cloud accumulation with 2D semantic mapping for accurate and efficient environmental understanding. Our Dual-Tempo action generation framework integrates zero-shot planning with policy-based fine control, and is further supported by an Adaptive Error Corrector that handles failure cases in real time. Experiments demonstrate that our approach outperforms state-of-the-art baselines in both perception accuracy and navigation robustness.", "authors": ["Shanshan Li", "Da Huang", "Yu He", "Yanwei Fu", "Yu-Gang Jiang", "Xiangyang Xue"], "year": 2025, "source": "arxiv", "published": "2025-11-21T13:12:13", "categories": ["cs.RO", "cs.AI", "cs.CV"], "design_phase": ["Analysis of task", "Concept design", "Implementation"], "ai_roles": ["decision-making", "planning", "evaluation", "optimization"], "representations": ["3D model", "2D semantic mapping", "code", "prototype"], "research_type": ["tool development", "methodology"], "summary_short": "The paper presents Task-Preferenced Multi-Demand-Driven Navigation (TP-MDDN), which addresses the complexities of real-world navigation tasks by integrating multiple sub-demands with task preferences. It introduces an autonomous decision-making system (AWMSystem) that utilizes advanced mapping and planning techniques to enhance navigation efficiency and accuracy.", "implications_for_design_research": ["Highlights the need for multi-faceted navigation systems in embodied AI.", "Suggests approaches for integrating user preferences into decision-making processes.", "Demonstrates the potential of combining various AI modules for improved task execution."], "tags": ["navigation", "autonomous-systems", "embodied-ai", "task-preference"]}
{"id": "http://arxiv.org/abs/2511.17229v1", "title": "Generating transition states of chemical reactions via distance-geometry-based flow matching", "abstract": "Transition states (TSs) are crucial for understanding reaction mechanisms, yet their exploration is limited by the complexity of experimental and computational approaches. Here we propose TS-DFM, a flow matching framework that predicts TSs from reactants and products. By operating in molecular distance geometry space, TS-DFM explicitly captures the dynamic changes of interatomic distances in chemical reactions. A network structure named TSDVNet is designed to learn the velocity field for generating TS geometries accurately. On the benchmark dataset Transition1X, TS-DFM outperforms the previous state-of-the-art method React-OT by 30\\% in structural accuracy. These predicted TSs provide high-quality initial structures, accelerating the convergence of CI-NEB optimization. Additionally, TS-DFM can identify alternative reaction paths. In our experiments, even a more favorable TS with lower energy barrier is discovered. Further tests on RGD1 dataset confirm its strong generalization ability on unseen molecules and reaction types, highlighting its potential for facilitating reaction exploration.", "authors": ["Yufei Luo", "Xiang Gu", "Jian Sun"], "year": 2025, "source": "arxiv", "published": "2025-11-21T13:15:25", "categories": ["cs.LG", "physics.chem-ph"], "design_phase": ["Analysis of task", "Concept design"], "ai_roles": ["optimization", "analysis"], "representations": ["3D model", "data visualization"], "research_type": ["tool development", "field study"], "summary_short": "The paper proposes TS-DFM, a framework for predicting transition states (TSs) in chemical reactions using distance geometry. It demonstrates improved accuracy in generating TS geometries, facilitating reaction exploration and optimization.", "implications_for_design_research": ["Highlights the role of AI in enhancing chemical reaction modeling.", "Demonstrates the effectiveness of flow matching in complex design tasks.", "Suggests potential applications of machine learning in predicting reaction pathways."], "tags": ["chemical-reactions", "machine-learning", "distance-geometry", "optimization"]}
{"id": "http://arxiv.org/abs/2511.17233v1", "title": "Algorithmic design and implementation considerations of deep MPC", "abstract": "Deep Model Predictive Control (Deep MPC) is an evolving field that integrates model predictive control and deep learning. This manuscript is focused on a particular approach, which employs deep neural network in the loop with MPC. This class of approaches distributes control authority between a neural network and an MPC controller, in such a way that the neural network learns the model uncertainties while the MPC handles constraints. The approach is appealing because training data collected while the system is in operation can be used to fine-tune the neural network, and MPC prevents unsafe behavior during those learning transients. This manuscript explains implementation challenges of Deep MPC, algorithmic way to distribute control authority and argues that a poor choice in distributing control authority may lead to poor performance. A reason of poor performance is explained through a numerical experiment on a four-wheeled skid-steer dynamics.", "authors": ["Prabhat K. Mishra", "Mateus V. Gasparino", "Girish Chowdhary"], "year": 2025, "source": "arxiv", "published": "2025-11-21T13:21:20", "categories": ["eess.SY", "cs.AI"], "design_phase": ["Analysis of task", "Embodiment design", "Implementation"], "ai_roles": ["evaluation", "optimization", "analysis"], "representations": ["model", "algorithm", "data"], "research_type": ["methodology", "tool development", "case study"], "summary_short": "The paper discusses Deep Model Predictive Control (Deep MPC), highlighting its integration of deep learning within model predictive control frameworks. It emphasizes the importance of proper distribution of control authority between neural networks and MPC to avoid performance issues, illustrated through numerical experiments on dynamics of a four-wheeled skid-steer.", "implications_for_design_research": ["Highlights the need for careful implementation strategies in AI-assisted control systems.", "Demonstrates the importance of leveraging real-time data for AI model improvement.", "Encourages exploration of hybrid approaches in control design."], "tags": ["deep-learning", "model-predictive-control", "algorithmic-design", "control-systems"]}
{"id": "http://arxiv.org/abs/2511.17238v1", "title": "Lost in Translation and Noise: A Deep Dive into the Failure Modes of VLMs on Real-World Tables", "abstract": "The impressive performance of VLMs is largely measured on benchmarks that fail to capture the complexities of real-world scenarios. Existing datasets for tabular QA, such as WikiTableQuestions and FinQA, are overwhelmingly monolingual (English) and present tables in a digitally perfect, clean format. This creates a significant gap between research and practice. To address this, we present \\textbf{MirageTVQA}, a new benchmark designed to evaluate VLMs on these exact dimensions. Featuring nearly 60,000 QA pairs across 24 languages, MirageTVQA challenges models with tables that are not only multilingual but also visually imperfect, incorporating realistic noise to mimic scanned documents. Our evaluation of the leading VLMs reveals two primary failure points: a severe degradation in performance (over 35\\% drop for the best models) when faced with visual noise and a consistent English-first bias where reasoning abilities fail to transfer to other languages. MirageTVQA provides a benchmark for measuring and driving progress towards more robust VLM models for table reasoning. The dataset and the code are available at: https://github.com/anshulsc/MirageTVQA.", "authors": ["Anshul Singh", "Rohan Chaudhary", "Gagneet Singh", "Abhay Kumary"], "year": 2025, "source": "arxiv", "published": "2025-11-21T13:32:56", "categories": ["cs.CL", "cs.AI", "cs.CV"], "design_phase": ["Analysis of task", "Implementation"], "ai_roles": ["evaluation", "analysis"], "representations": ["data visualization", "text"], "research_type": ["tool development", "theory building"], "summary_short": "This paper presents MirageTVQA, a new benchmark designed to evaluate Visual Language Models (VLMs) on real-world table data that incorporates visual noise and multilingual challenges. The study reveals significant performance degradation in leading VLMs when faced with such complex scenarios, highlighting a gap between academic benchmarks and practical applications.", "implications_for_design_research": ["Highlights the need for realistic datasets in evaluating AI models.", "Calls for the development of multilingual and visually-imperfect benchmarks.", "Suggests that performance metrics should consider real-world complexity."], "tags": ["benchmarking", "visual-language-models", "multilingual-data", "evaluation-methods"]}
{"id": "http://arxiv.org/abs/2511.17240v1", "title": "Fast Decoding for Non-Adaptive Learning of Erdős--Rényi Random Graphs", "abstract": "We study the problem of learning an unknown graph via group queries on node subsets, where each query reports whether at least one edge is present among the queried nodes. In general, learning arbitrary graphs with \\(n\\) nodes and \\(k\\) edges is hard in the non-adaptive setting, requiring \\(Ω\\big(\\min\\{k^2\\log n,\\,n^2\\}\\big)\\) tests even when a small error probability is allowed. We focus on learning Erdős--Rényi (ER) graphs \\(G\\sim\\ER(n,q)\\) in the non-adaptive setting, where the expected number of edges is \\(\\bar{k}=q\\binom{n}{2}\\), and we aim to design an efficient testing--decoding scheme achieving asymptotically vanishing error probability. Prior work (Li--Fresacher--Scarlett, NeurIPS 2019) presents a testing--decoding scheme that attains an order-optimal number of tests \\(O(\\bar{k}\\log n)\\) but incurs \\(Ω(n^2)\\) decoding time, whereas their proposed sublinear-time algorithm incurs an extra \\((\\log \\bar{k})(\\log n)\\) factor in the number of tests. We extend the binary splitting approach, recently developed for non-adaptive group testing, to the ER graph learning setting, and prove that the edge set can be recovered with high probability using \\(O(\\bar{k}\\log n)\\) tests while attaining decoding time \\(O(\\bar{k}^{1+δ}\\log n)\\) for any fixed \\(δ>0\\).", "authors": ["Hoang Ta", "Jonathan Scarlett"], "year": 2025, "source": "arxiv", "published": "2025-11-21T13:34:29", "categories": ["cs.IT", "cs.DM", "cs.LG", "math.PR"], "design_phase": [], "ai_roles": [], "representations": [], "research_type": ["theory building"], "summary_short": "The paper explores non-adaptive learning of Erdős--Rényi random graphs using group queries to report edge presence. It presents an efficient testing-decodng scheme that reduces decoding time while maintaining a low error probability.", "implications_for_design_research": [], "tags": ["graph-learning", "error-reduction", "group-query"]}
{"id": "http://arxiv.org/abs/2511.17242v1", "title": "Equivariant-Aware Structured Pruning for Efficient Edge Deployment: A Comprehensive Framework with Adaptive Fine-Tuning", "abstract": "This paper presents a novel framework combining group equivariant convolutional neural networks (G-CNNs) with equivariant-aware structured pruning to produce compact, transformation-invariant models for resource-constrained environments. Equivariance to rotations is achieved through the C4 cyclic group via the e2cnn library,enabling consistent performance under geometric transformations while reducing computational overhead.\n  Our approach introduces structured pruning that preserves equivariant properties by analyzing e2cnn layer structure and applying neuron-level pruning to fully connected components. To mitigate accuracy degradation, we implement adaptive fine-tuning that automatically triggers when accuracy drop exceeds 2%, using early stopping and learning rate scheduling for efficient recovery. The framework includes dynamic INT8 quantization and a comprehensive pipeline encompassing training, knowledge distillation, structured pruning, fine-tuning, and quantization.\n  We evaluate our method on satellite imagery (EuroSAT) and standard benchmarks (CIFAR-10, Rotated MNIST) demonstrating effectiveness across diverse domains. Experimental results show 29.3% parameter reduction with significant accuracy recovery, demonstrating that structured pruning of equivariant networks achieves substantial compression while maintaining geometric robustness. Our pipeline provides a reproducible framework for optimizing equivariant models, bridging the gap between group-theoretic network design and practical deployment constraints, with particular relevance to satellite imagery analysis and geometric vision tasks.", "authors": ["Mohammed Alnemari"], "year": 2025, "source": "arxiv", "published": "2025-11-21T13:41:47", "categories": ["cs.CV", "cs.LG"], "design_phase": ["Embodiment design", "Implementation"], "ai_roles": ["optimization", "evaluation", "analysis"], "representations": ["code", "data visualization"], "research_type": ["tool development", "methodology", "case study"], "summary_short": "This paper introduces a framework that integrates group equivariant convolutional neural networks with structured pruning to create efficient models for resource-constrained environments. The method achieves significant parameter reduction while maintaining accuracy and robustness against geometric transformations, particularly in satellite imagery analysis.", "implications_for_design_research": ["Demonstrates the importance of equivariance in model design for practical applications.", "Highlights the interplay between model compression techniques and accuracy maintenance.", "Contributes a reproducible framework for deploying complex neural architectures in real-world conditions."], "tags": ["equivariant-learning", "structured-pruning", "neural-networks", "resource-efficiency"]}
{"id": "http://arxiv.org/abs/2511.17246v1", "title": "Mixed Reality Scenic Live Streaming for Cultural Heritage: Visual Interactions in a Historic Landscape", "abstract": "Scenic Live Streams (SLS), capturing real-world scenic sites from fixed cameras without streamers, have gained increasing popularity recently. They afford unique real-time lenses into remote sites for viewers' synchronous and collective engagement. Foregrounding its lack of dynamism and interactivity, we aim to maximize the potential of SLS by making it interactive. Namely MRSLS, we overlaid plain SLS with interactive Mixed Reality content that matches the site's geographical structures and local cultural backgrounds. We further highlight the substantial benefit of MRSLS to cultural heritage site interactions, and we demonstrate this design proposal with an MRSLS prototype at a UNESCO-listed heritage site in China. The design process includes an interview (N=6) to pinpoint local scenery and culture, as well as two iterative design studies (N=15, 14). A mixed-methods, between-subjects study (N=43, 37) shows that MRSLS affords immersive scenery appreciation, effective cultural imprints, and vivid shared experience. With its balance between cultural, participatory, and authentic attributes, we appeal for more HCI attention to (MR)SLS as an under-explored design space.", "authors": ["Zeyu Huang", "Zuyu Xu", "Yuanhao Zhang", "Chengzhong Liu", "Yanwei Zhao", "Chuhan Shi", "Jason Chen Zhao", "Xiaojuan Ma"], "year": 2025, "source": "arxiv", "published": "2025-11-21T13:46:42", "categories": ["cs.HC"], "design_phase": [], "ai_roles": [], "representations": [], "research_type": [], "summary_short": "Scenic Live Streams (SLS), capturing real-world scenic sites from fixed cameras without streamers, have gained increasing popularity recently. They afford unique real-time lenses into remote sites for viewers' synchronous and collective engagement. Foregrounding its lack of dynamism and interactivit", "implications_for_design_research": [], "tags": []}
{"id": "http://arxiv.org/abs/2511.17249v1", "title": "FlexiFlow: decomposable flow matching for generation of flexible molecular ensemble", "abstract": "Sampling useful three-dimensional molecular structures along with their most favorable conformations is a key challenge in drug discovery. Current state-of-the-art 3D de-novo design flow matching or diffusion-based models are limited to generating a single conformation. However, the conformational landscape of a molecule determines its observable properties and how tightly it is able to bind to a given protein target. By generating a representative set of low-energy conformers, we can more directly assess these properties and potentially improve the ability to generate molecules with desired thermodynamic observables. Towards this aim, we propose FlexiFlow, a novel architecture that extends flow-matching models, allowing for the joint sampling of molecules along with multiple conformations while preserving both equivariance and permutation invariance. We demonstrate the effectiveness of our approach on the QM9 and GEOM Drugs datasets, achieving state-of-the-art results in molecular generation tasks. Our results show that FlexiFlow can generate valid, unstrained, unique, and novel molecules with high fidelity to the training data distribution, while also capturing the conformational diversity of molecules. Moreover, we show that our model can generate conformational ensembles that provide similar coverage to state-of-the-art physics-based methods at a fraction of the inference time. Finally, FlexiFlow can be successfully transferred to the protein-conditioned ligand generation task, even when the dataset contains only static pockets without accompanying conformations.", "authors": ["Riccardo Tedoldi", "Ola Engkvist", "Patrick Bryant", "Hossein Azizpour", "Jon Paul Janet", "Alessandro Tibo"], "year": 2025, "source": "arxiv", "published": "2025-11-21T13:50:54", "categories": ["cs.LG"], "design_phase": ["Establishing a need", "Concept design", "Implementation"], "ai_roles": ["generation", "evaluation", "optimization"], "representations": ["data visualization", "3D model", "code"], "research_type": ["methodology", "tool development"], "summary_short": "The paper presents FlexiFlow, a novel architecture designed to generate flexible molecular ensembles by sampling various conformations. It showcases advancements in molecular generation tasks, achieving superior results while preserving conformational diversity, thus enhancing drug discovery processes.", "implications_for_design_research": ["Highlights the importance of conformational diversity in molecular design.", "Demonstrates potential for AI-driven methods to improve drug discovery efficiency.", "Suggests new architectural designs can enhance existing methodologies."], "tags": ["molecular-design", "drug-discovery", "ai-in-medicine", "generative-models"]}
{"id": "http://arxiv.org/abs/2511.17265v1", "title": "DISCA: A Digital In-memory Stochastic Computing Architecture Using A Compressed Bent-Pyramid Format", "abstract": "Nowadays, we are witnessing an Artificial Intelligence revolution that dominates the technology landscape in various application domains, such as healthcare, robotics, automotive, security, and defense. Massive-scale AI models, which mimic the human brain's functionality, typically feature millions and even billions of parameters through data-intensive matrix multiplication tasks. While conventional Von-Neumann architectures struggle with the memory wall and the end of Moore's Law, these AI applications are migrating rapidly towards the edge, such as in robotics and unmanned aerial vehicles for surveillance, thereby adding more constraints to the hardware budget of AI architectures at the edge. Although in-memory computing has been proposed as a promising solution for the memory wall, both analog and digital in-memory computing architectures suffer from substantial degradation of the proposed benefits due to various design limitations. We propose a new digital in-memory stochastic computing architecture, DISCA, utilizing a compressed version of the quasi-stochastic Bent-Pyramid data format. DISCA inherits the same computational simplicity of analog computing, while preserving the same scalability, productivity, and reliability of digital systems. Post-layout modeling results of DISCA show an energy efficiency of 3.59 TOPS/W per bit at 500 MHz using a commercial 180nm CMOS technology. Therefore, DISCA significantly improves the energy efficiency for matrix multiplication workloads by orders of magnitude if scaled and compared to its counterpart architectures.", "authors": ["Shady Agwa", "Yikang Shen", "Shiwei Wang", "Themis Prodromakis"], "year": 2025, "source": "arxiv", "published": "2025-11-21T14:13:16", "categories": ["cs.AR", "cs.AI", "cs.ET", "cs.PF"], "design_phase": ["Establishing a need", "Embodiment design"], "ai_roles": ["optimization", "simulation"], "representations": ["data visualization", "code"], "research_type": ["tool development", "theory building"], "summary_short": "This paper introduces DISCA, a novel digital in-memory stochastic computing architecture designed to overcome the limitations of traditional computing architectures. By employing a compressed Bent-Pyramid format, DISCA enhances energy efficiency for matrix multiplication tasks, making it ideal for edge AI applications.", "implications_for_design_research": ["Highlights the necessity for innovative architectures in edge AI applications.", "Demonstrates the potential of in-memory computing solutions for improved efficiency.", "Encourages exploration of alternative data formats in computing architectures."], "tags": ["in-memory-computing", "stochastic-computing", "edge-ai"]}
{"id": "http://arxiv.org/abs/2511.17331v1", "title": "AI Workers, Geopolitics, and Algorithmic Collective Action", "abstract": "According to the theory of International Political Economy (IPE), states are often incentivized to rely on rather than constrain powerful corporations. For this reason, IPE provides a useful lens to explain why efforts to govern Artificial Intelligence (AI) at the international and national levels have thus far been developed, applied, and enforced unevenly. Building on recent work that explores how AI companies engage in geopolitics, this position paper argues that some AI workers can be considered actors of geopolitics. It makes the timely case that governance alone cannot ensure responsible, ethical, or robust AI development and use, and greater attention should be paid to bottom-up interventions at the site of AI development. AI workers themselves should be situated as individual agents of change, especially when considering their potential to foster Algorithmic Collective Action (ACA). Drawing on methods of Participatory Design (PD), this paper proposes engaging AI workers as sources of knowledge, relative power, and intentionality to encourage more responsible and just AI development and create the conditions that can facilitate ACA.", "authors": ["Sydney Reis"], "year": 2025, "source": "arxiv", "published": "2025-11-21T15:52:44", "categories": ["cs.CY", "cs.AI", "cs.HC"], "design_phase": [], "ai_roles": [], "representations": [], "research_type": [], "summary_short": "According to the theory of International Political Economy (IPE), states are often incentivized to rely on rather than constrain powerful corporations. For this reason, IPE provides a useful lens to explain why efforts to govern Artificial Intelligence (AI) at the international and national levels h", "implications_for_design_research": [], "tags": []}
{"id": "http://arxiv.org/abs/2511.17332v1", "title": "Agentifying Agentic AI", "abstract": "Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize this vision, its assumptions about agency must be complemented by explicit models of cognition, cooperation, and governance. This paper argues that the conceptual tools developed within the Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI architectures, communication protocols, mechanism design, and institutional modelling, provide precisely such a foundation. By aligning adaptive, data-driven approaches with structured models of reasoning and coordination, we outline a path toward agentic systems that are not only capable and flexible, but also transparent, cooperative, and accountable. The result is a perspective on agency that bridges formal theory and practical autonomy.", "authors": ["Virginia Dignum", "Frank Dignum"], "year": 2025, "source": "arxiv", "published": "2025-11-21T15:54:44", "categories": ["cs.AI", "cs.MA"], "design_phase": ["Establishing a need", "Analysis of task", "Concept design"], "ai_roles": ["co-creation", "interaction", "analysis"], "representations": ["text", "data visualization", "formal models"], "research_type": ["theory building", "methodology"], "summary_short": "The paper discusses the need for explicit models of cognition and cooperation in developing agentic AI systems. It highlights tools from the AAMAS community that can support creating autonomous systems that are capable, transparent, and accountable.", "implications_for_design_research": ["Emphasizes the importance of integrating formal theory with practical applications in AI design.", "Suggests that clarity in agency models can lead to more accountable AI systems.", "Promotes collaboration across different AI-focused communities to enhance system capabilities."], "tags": ["agentic-ai", "multi-agent-systems", "autonomous-systems"]}
{"id": "http://arxiv.org/abs/2511.17339v1", "title": "ReBaPL: Repulsive Bayesian Prompt Learning", "abstract": "Prompt learning has emerged as an effective technique for fine-tuning large-scale foundation models for downstream tasks. However, conventional prompt tuning methods are prone to overfitting and can struggle with out-of-distribution generalization. To address these limitations, Bayesian prompt learning has been proposed, which frames prompt optimization as a Bayesian inference problem to enhance robustness. This paper introduces Repulsive Bayesian Prompt Learning (ReBaPL), a novel method for Bayesian prompt learning, designed to efficiently explore the complex and often multimodal posterior landscape of prompts. Our method integrates a cyclical step-size schedule with a stochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm, enabling alternating phases of exploration to discover new modes, and exploitation to refine existing modes. Furthermore, we introduce a repulsive force derived from a potential function over probability metrics (including Maximum Mean Discrepancy and Wasserstein distance) computed on the distributions of representations produced by different prompts. This representation-space repulsion diversifies exploration and prevents premature collapse to a single mode. Our approach allows for a more comprehensive characterization of the prompt posterior distribution, leading to improved generalization. In contrast to prior Bayesian prompt learning methods, our method provides a modular plug-and-play Bayesian extension of any existing prompt learning method based on maximum likelihood estimation. We demonstrate the efficacy of ReBaPL on several benchmark datasets, showing superior performance over state-of-the-art methods for prompt learning.", "authors": ["Yassir Bendou", "Omar Ezzahir", "Eduardo Fernandes Montesuma", "Gabriel Mahuas", "Victoria Shevchenko", "Mike Gartrell"], "year": 2025, "source": "arxiv", "published": "2025-11-21T16:00:13", "categories": ["cs.LG"], "design_phase": ["Concept design", "Implementation"], "ai_roles": ["optimization", "evaluation", "analysis"], "representations": ["data visualization", "code"], "research_type": ["tool development", "theory building"], "summary_short": "This paper presents Repulsive Bayesian Prompt Learning (ReBaPL), a novel method for enhancing Bayesian prompt learning in large-scale models. By integrating a cyclical step-size schedule and a stochastic gradient approach, it improves robustness and generalization compared to conventional methods.", "implications_for_design_research": ["Encourages exploration of advanced Bayesian techniques for prompt optimization.", "Highlights the need for methods addressing overfitting in AI models.", "Demonstrates the potential for modular extensions to existing AI tools.", "Emphasizes the importance of diversifying exploration strategies in model training."], "tags": ["bayesian-prompt-learning", "optimization-techniques", "ai-models"]}
{"id": "http://arxiv.org/abs/2511.17372v1", "title": "Quantum Masked Autoencoders for Vision Learning", "abstract": "Classical autoencoders are widely used to learn features of input data. To improve the feature learning, classical masked autoencoders extend classical autoencoders to learn the features of the original input sample in the presence of masked-out data. While quantum autoencoders exist, there is no design and implementation of quantum masked autoencoders that can leverage the benefits of quantum computing and quantum autoencoders. In this paper, we propose quantum masked autoencoders (QMAEs) that can effectively learn missing features of a data sample within quantum states instead of classical embeddings. We showcase that our QMAE architecture can learn the masked features of an image and can reconstruct the masked input image with improved visual fidelity in MNIST images. Experimental evaluation highlights that QMAE can significantly outperform (12.86% on average) in classification accuracy compared to state-of-the-art quantum autoencoders in the presence of masks.", "authors": ["Emma Andrews", "Prabhat Mishra"], "year": 2025, "source": "arxiv", "published": "2025-11-21T16:37:18", "categories": ["quant-ph", "cs.AI", "cs.LG"], "design_phase": ["Implementation"], "ai_roles": ["evaluation", "analysis", "optimization"], "representations": ["data visualization", "prototype"], "research_type": ["tool development", "methodology"], "summary_short": "This paper introduces quantum masked autoencoders (QMAEs) to enhance feature learning in the presence of masked data within quantum states. The results demonstrate that QMAEs can significantly improve classification accuracy in visual tasks, outperforming classical and state-of-the-art quantum autoencoders.", "implications_for_design_research": ["Encourages exploration of quantum techniques in design tools", "Highlights the potential of quantum computing for data reconstruction tasks", "Promotes the integration of masking strategies in feature learning"], "tags": ["quantum-autoencoders", "feature-learning", "masked-data"]}
{"id": "http://arxiv.org/abs/2511.17393v1", "title": "Designing and Generating Diverse, Equitable Face Image Datasets for Face Verification Tasks", "abstract": "Face verification is a significant component of identity authentication in various applications including online banking and secure access to personal devices. The majority of the existing face image datasets often suffer from notable biases related to race, gender, and other demographic characteristics, limiting the effectiveness and fairness of face verification systems. In response to these challenges, we propose a comprehensive methodology that integrates advanced generative models to create varied and diverse high-quality synthetic face images. This methodology emphasizes the representation of a diverse range of facial traits, ensuring adherence to characteristics permissible in identity card photographs. Furthermore, we introduce the Diverse and Inclusive Faces for Verification (DIF-V) dataset, comprising 27,780 images of 926 unique identities, designed as a benchmark for future research in face verification. Our analysis reveals that existing verification models exhibit biases toward certain genders and races, and notably, applying identity style modifications negatively impacts model performance. By tackling the inherent inequities in existing datasets, this work not only enriches the discussion on diversity and ethics in artificial intelligence but also lays the foundation for developing more inclusive and reliable face verification technologies", "authors": ["Georgia Baltsou", "Ioannis Sarridis", "Christos Koutlis", "Symeon Papadopoulos"], "year": 2025, "source": "arxiv", "published": "2025-11-21T16:53:08", "categories": ["cs.CV", "cs.AI"], "design_phase": ["Establishing a need", "Analysis of task", "Concept design"], "ai_roles": ["idea generation", "evaluation", "analysis"], "representations": ["image", "data visualization"], "research_type": ["methodology", "tool development", "case study"], "summary_short": "This paper addresses biases in existing face image datasets used for face verification tasks by proposing a methodology that uses generative models to create a diverse dataset. The resulting Diverse and Inclusive Faces for Verification (DIF-V) dataset serves as a benchmark for future research while highlighting the ethical concerns surrounding bias in AI technologies.", "implications_for_design_research": ["Emphasizes the importance of diversity and equity in AI datasets", "Suggests methods for generating inclusive datasets to enhance AI fairness", "Highlights the need for ongoing analysis of biases in machine learning models"], "tags": ["face-verification", "generative-models", "diversity-in-ai"]}
{"id": "http://arxiv.org/abs/2511.17401v1", "title": "Feasibility of Embodied Dynamics Based Bayesian Learning for Continuous Pursuit Motion Control of Assistive Mobile Robots in the Built Environment", "abstract": "Non-invasive electroencephalography (EEG)-based brain-computer interfaces (BCIs) offer an intuitive means for individuals with severe motor impairments to independently operate assistive robotic wheelchairs and navigate built environments. Despite considerable progress in BCI research, most current motion control systems are limited to discrete commands, rather than supporting continuous pursuit, where users can freely adjust speed and direction in real time. Such natural mobility control is, however, essential for wheelchair users to navigate complex public spaces, such as transit stations, airports, hospitals, and indoor corridors, to interact socially with the dynamic populations with agility, and to move flexibly and comfortably as autonomous driving is refined to allow movement at will. In this study, we address the gap of continuous pursuit motion control in BCIs by proposing and validating a brain-inspired Bayesian inference framework, where embodied dynamics in acceleration-based motor representations are decoded. This approach contrasts with conventional kinematics-level decoding and deep learning-based methods. Using a public dataset with sixteen hours of EEG from four subjects performing motor imagery-based target-following, we demonstrate that our method, utilizing Automatic Relevance Determination for feature selection and continual online learning, reduces the normalized mean squared error between predicted and true velocities by 72% compared to autoregressive and EEGNet-based methods in a session-accumulative transfer learning setting. Theoretically, these findings empirically support embodied cognition theory and reveal the brain's intrinsic motor control dynamics in an embodied and predictive nature. Practically, grounding EEG decoding in the same dynamical principles that govern biological motion offers a promising path toward more stable and intuitive BCI control.", "authors": ["Xiaoshan Zhou", "Carol C. Menassa", "Vineet R. Kamat"], "year": 2025, "source": "arxiv", "published": "2025-11-21T17:00:48", "categories": ["cs.RO", "cs.HC"], "design_phase": ["Analysis of task", "Concept design", "Implementation"], "ai_roles": ["evaluation", "optimization", "analysis"], "representations": ["data visualization", "code", "interface"], "research_type": ["tool development", "theory building", "case study"], "summary_short": "This study explores a brain-inspired Bayesian framework for continuous pursuit motion control in brain-computer interfaces to enhance mobility for individuals with motor impairments. It demonstrates significant improvements in predicting user intent through embodied dynamics and sets a foundation for more intuitive and stable BCI control systems.", "implications_for_design_research": ["Advancements in BCI design can leverage embodied cognition principles.", "Continuous motion control frameworks can enhance user experience in assistive tech.", "Data-driven approaches in cognitive and motor representations provide insights for future systems."], "tags": ["brain-computer-interface", "embodied-cognition", "motion-control", "assistive-technology"]}
{"id": "http://arxiv.org/abs/2511.17435v1", "title": "Multi-Agent Pointer Transformer: Seq-to-Seq Reinforcement Learning for Multi-Vehicle Dynamic Pickup-Delivery Problems", "abstract": "This paper addresses the cooperative Multi-Vehicle Dynamic Pickup and Delivery Problem with Stochastic Requests (MVDPDPSR) and proposes an end-to-end centralized decision-making framework based on sequence-to-sequence, named Multi-Agent Pointer Transformer (MAPT). MVDPDPSR is an extension of the vehicle routing problem and a spatio-temporal system optimization problem, widely applied in scenarios such as on-demand delivery. Classical operations research methods face bottlenecks in computational complexity and time efficiency when handling large-scale dynamic problems. Although existing reinforcement learning methods have achieved some progress, they still encounter several challenges: 1) Independent decoding across multiple vehicles fails to model joint action distributions; 2) The feature extraction network struggles to capture inter-entity relationships; 3) The joint action space is exponentially large. To address these issues, we designed the MAPT framework, which employs a Transformer Encoder to extract entity representations, combines a Transformer Decoder with a Pointer Network to generate joint action sequences in an AutoRegressive manner, and introduces a Relation-Aware Attention module to capture inter-entity relationships. Additionally, we guide the model's decision-making using informative priors to facilitate effective exploration. Experiments on 8 datasets demonstrate that MAPT significantly outperforms existing baseline methods in terms of performance and exhibits substantial computational time advantages compared to classical operations research methods.", "authors": ["Zengyu Zou", "Jingyuan Wang", "Yixuan Huang", "Junjie Wu"], "year": 2025, "source": "arxiv", "published": "2025-11-21T17:32:10", "categories": ["cs.LG"], "design_phase": ["Analysis of task", "Concept design", "Implementation"], "ai_roles": ["optimization", "evaluation", "interaction"], "representations": ["data visualization", "code", "prototype"], "research_type": ["tool development", "theory building", "case study"], "summary_short": "This paper introduces the Multi-Agent Pointer Transformer (MAPT), a centralized decision-making framework for addressing the Multi-Vehicle Dynamic Pickup and Delivery Problem with Stochastic Requests. Through the use of sequence-to-sequence reinforcement learning, the framework improves upon existing methods by capturing inter-entity relationships and efficiently generating joint action sequences.", "implications_for_design_research": ["Demonstrates the effectiveness of sequence-to-sequence models in complex decision-making tasks.", "Highlights the importance of capturing inter-entity relationships in multi-agent systems.", "Suggests potential for using advanced AI techniques to optimize operational efficiency in logistics."], "tags": ["reinforcement-learning", "multi-agent-systems", "logistics-optimization", "transportation"]}
{"id": "http://arxiv.org/abs/2511.17443v1", "title": "GRAPHIC--Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity", "abstract": "Artificial Intelligence (AI) has been increasingly applied to creative domains, leading to the development of systems that collaborate with humans in design processes. In Graphic Design, integrating computational systems into co-creative workflows presents specific challenges, as it requires balancing scientific rigour with the subjective and visual nature of design practice. Following the PRISMA methodology, we identified 872 articles, resulting in a final corpus of 71 publications describing 68 unique systems. Based on this review, we introduce GRAPHIC (Guidelines for Reviewing Algorithmic Practices in Human-centred Design and Interaction for Creativity), a framework for analysing AI-based systems applied to Graphic Design. Its goal is to understand how current systems support human-AI collaboration in the Graphic Design discipline. The framework comprises main dimensions, which our analysis revealed to be essential across diverse system types: (1) Collaborative Panorama, (2) Processes and Modalities, and (3) Graphic Design Principles. Its application revealed research gaps, including the need to balance initiative and control between agents, improve communication through explainable interaction models, and promote systems that support transformational creativity grounded in core design principles.", "authors": ["Joana Rovira Martins", "Pedro Martins", "Ana Boavida"], "year": 2025, "source": "arxiv", "published": "2025-11-21T17:42:09", "categories": ["cs.HC", "cs.AI", "cs.GR"], "design_phase": [], "ai_roles": [], "representations": [], "research_type": [], "summary_short": "Artificial Intelligence (AI) has been increasingly applied to creative domains, leading to the development of systems that collaborate with humans in design processes. In Graphic Design, integrating computational systems into co-creative workflows presents specific challenges, as it requires balanci", "implications_for_design_research": [], "tags": []}
{"id": "http://arxiv.org/abs/2511.17446v1", "title": "Unmasking Airborne Threats: Guided-Transformers for Portable Aerosol Mass Spectrometry", "abstract": "Matrix Assisted Laser Desorption/Ionization Mass Spectrometry (MALDI-MS) is a cornerstone in biomolecular analysis, offering precise identification of pathogens through unique mass spectral signatures. Yet, its reliance on labor-intensive sample preparation and multi-shot spectral averaging restricts its use to laboratory settings, rendering it impractical for real-time environmental monitoring. These limitations are especially pronounced in emerging aerosol MALDI-MS systems, where autonomous sampling generates noisy spectra for unknown aerosol analytes, requiring single-shot detection for effective analysis. Addressing these challenges, we propose the Mass Spectral Dictionary-Guided Transformer (MS-DGFormer): a data-driven framework that redefines spectral analysis by directly processing raw, minimally prepared mass spectral data. MS-DGFormer leverages a transformer architecture, designed to capture the long-range dependencies inherent in these time-series spectra. To enhance feature extraction, we introduce a novel dictionary encoder that integrates denoised spectral information derived from Singular Value Decomposition (SVD), enabling the model to discern critical biomolecular patterns from single-shot spectra with robust performance. This innovation provides a system to achieve superior pathogen identification from aerosol samples, facilitating autonomous, real-time analysis in field conditions. By eliminating the need for extensive preprocessing, our method unlocks the potential for portable, deployable MALDI-MS platforms, revolutionizing environmental pathogen detection and rapid response to biological threats.", "authors": ["Kyle M. Regan", "Michael McLoughlin", "Wayne A. Bryden", "Gonzalo R. Arce"], "year": 2025, "source": "arxiv", "published": "2025-11-21T17:45:00", "categories": ["cs.LG"], "design_phase": ["Analysis of task", "Concept design", "Implementation"], "ai_roles": ["evaluation", "optimization", "analysis"], "representations": ["data visualization", "code", "prototype"], "research_type": ["methodology", "tool development"], "summary_short": "The paper presents the Mass Spectral Dictionary-Guided Transformer (MS-DGFormer), a novel framework designed to enhance the analysis of raw mass spectral data for environmental monitoring. By utilizing a transformer architecture and a unique dictionary encoder, this approach allows for superior real-time pathogen identification from aerosol samples, streamlining the usually labor-intensive process.", "implications_for_design_research": ["Encourages the development of portable analytical tools for environmental applications.", "Demonstrates the effectiveness of AI in optimizing real-time data analysis.", "Highlights the importance of reducing preprocessing steps in analytical methods."], "tags": ["mass-spectrometry", "ai-optimization", "real-time-analysis"]}
{"id": "http://arxiv.org/abs/2511.17450v1", "title": "Planning with Sketch-Guided Verification for Physics-Aware Video Generation", "abstract": "Recent video generation approaches increasingly rely on planning intermediate control signals such as object trajectories to improve temporal coherence and motion fidelity. However, these methods mostly employ single-shot plans that are typically limited to simple motions, or iterative refinement which requires multiple calls to the video generator, incuring high computational cost. To overcome these limitations, we propose SketchVerify, a training-free, sketch-verification-based planning framework that improves motion planning quality with more dynamically coherent trajectories (i.e., physically plausible and instruction-consistent motions) prior to full video generation by introducing a test-time sampling and verification loop. Given a prompt and a reference image, our method predicts multiple candidate motion plans and ranks them using a vision-language verifier that jointly evaluates semantic alignment with the instruction and physical plausibility. To efficiently score candidate motion plans, we render each trajectory as a lightweight video sketch by compositing objects over a static background, which bypasses the need for expensive, repeated diffusion-based synthesis while achieving comparable performance. We iteratively refine the motion plan until a satisfactory one is identified, which is then passed to the trajectory-conditioned generator for final synthesis. Experiments on WorldModelBench and PhyWorldBench demonstrate that our method significantly improves motion quality, physical realism, and long-term consistency compared to competitive baselines while being substantially more efficient. Our ablation study further shows that scaling up the number of trajectory candidates consistently enhances overall performance.", "authors": ["Yidong Huang", "Zun Wang", "Han Lin", "Dong-Ki Kim", "Shayegan Omidshafiei", "Jaehong Yoon", "Yue Zhang", "Mohit Bansal"], "year": 2025, "source": "arxiv", "published": "2025-11-21T17:48:02", "categories": ["cs.CV", "cs.AI", "cs.CL"], "design_phase": [], "ai_roles": [], "representations": [], "research_type": [], "summary_short": "Recent video generation approaches increasingly rely on planning intermediate control signals such as object trajectories to improve temporal coherence and motion fidelity. However, these methods mostly employ single-shot plans that are typically limited to simple motions, or iterative refinement wh", "implications_for_design_research": [], "tags": []}
